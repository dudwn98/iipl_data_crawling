{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DaumNewsCrawling.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOZ/GC49WpIokPQnzEa9a2m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dudwn98/iipl_data_crawling/blob/main/DaumNewsCrawling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O970V1SiutJr"
      },
      "source": [
        "import requests\r\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yHxPYXlyRxo"
      },
      "source": [
        "## 제목"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2kRzAazw1UK"
      },
      "source": [
        "url = \"https://news.v.daum.net/v/20210129180009136\"\r\n",
        "resp = requests.get(url)\r\n",
        "html = BeautifulSoup(resp.content, 'lxml')\r\n",
        "html\r\n",
        "f = open('result.csv','w', encoding='UTF-8')\r\n",
        "\r\n",
        "f.write(\"제목, 원문, 댓글\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hMDcKU6uxX6"
      },
      "source": [
        "def get_news_title(news_id):\r\n",
        "    url = 'https://news.v.daum.net/v/{}'.format(news_id)\r\n",
        "    resp = BeautifulSoup(requests.get(url).text, 'lxml')\r\n",
        "    title = resp.find(\"h3\", {\"class\": \"tit_view\"} )\r\n",
        "    \r\n",
        "    if title:\r\n",
        "        f.write(title.get_text())\r\n",
        "        return title.get_text()\r\n",
        "    return \"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WkKVj_BwrSH"
      },
      "source": [
        "get_news_title('20210129180009136')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTW7rwBix0Ut"
      },
      "source": [
        "get_news_title('20210129164803052')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuX4txHOyP3e"
      },
      "source": [
        "## 본문"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ySODDjHwsi0"
      },
      "source": [
        "def get_news_content(news_id):\r\n",
        "    url = 'https://news.v.daum.net/v/{}'.format(news_id)\r\n",
        "    resp = BeautifulSoup(requests.get(url).text, 'lxml')\r\n",
        "\r\n",
        "    content = ''\r\n",
        "    contents = resp.find(\"div\", {\"id\":\"harmonyContainer\"}).findAll(\"p\")\r\n",
        "    for p in contents:\r\n",
        "        content += p.get_text()\r\n",
        "    f.write(content)\r\n",
        "    print(content)\r\n",
        "    return content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUxvS_qKzdYD"
      },
      "source": [
        "get_news_content('20210129180009136')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPXDoZjKzOem"
      },
      "source": [
        "get_news_content(20210129164803052)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITQLlq8EzkDf"
      },
      "source": [
        "## 댓글"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1qfd4jJzTt8"
      },
      "source": [
        "url = \"https://comment.daum.net/apis/v1/posts/153207539/comments?parentId=0&offset=3&limit=10&sort=POPULAR&isInitial=false&hasNext=true&randomSeed=1611943940\"\r\n",
        "\r\n",
        "resp = requests.get(url)\r\n",
        "resp.json()\r\n",
        "if resp.status_code == 200:\r\n",
        "    json_data = resp.json()\r\n",
        "    comments = ''\r\n",
        "    for comment in json_data:\r\n",
        "        comments += comment['content'].replace(\"\\n\", \"/\").replace(\",\",\"\")\r\n",
        "    print(comments)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sda3lzuU0yoJ"
      },
      "source": [
        "f = open('test.csv','w')\r\n",
        "f.write(\"제목, 원문, 댓글\\n\")\r\n",
        "\r\n",
        "def get_news_title(news_id):\r\n",
        "    url = 'https://news.v.daum.net/v/{}'.format(news_id)\r\n",
        "    resp = BeautifulSoup(requests.get(url).text, 'lxml')\r\n",
        "\r\n",
        "    title = resp.find(\"h3\", {\"class\": \"tit_view\"} ).get_text()\r\n",
        "    return title.replace(',',' ')\r\n",
        "\r\n",
        "def get_news_content(news_id):\r\n",
        "    url = 'https://news.v.daum.net/v/{}'.format(news_id)\r\n",
        "    resp = BeautifulSoup(requests.get(url).text, 'lxml')\r\n",
        "\r\n",
        "    content = ''\r\n",
        "    contents = resp.find(\"div\", {\"id\":\"harmonyContainer\"}).findAll(\"p\")\r\n",
        "    for p in contents:\r\n",
        "        content += p.get_text()\r\n",
        "    return content.replace(\"\\n\", \"/\").replace(\",\",\"\")\r\n",
        "\r\n",
        "def get_news_comments(news_id):\r\n",
        "    url = 'https://comment.daum.net/apis/v1/posts/153207539/comments?parentId=0&offset=3&limit=10&sort=POPULAR&isInitial=false&hasNext=true&randomSeed=1611943940'\r\n",
        "    resp = requests.get(url)\r\n",
        "\r\n",
        "    resp.json()\r\n",
        "    if resp.status_code == 200:\r\n",
        "        json_data = resp.json()\r\n",
        "        comments = ''\r\n",
        "        for comment in json_data:\r\n",
        "            comments += comment['content']\r\n",
        "    comments = comments.replace(\"\\n\", \"/\").replace(\",\",\"\")\r\n",
        "    return comments\r\n",
        "\r\n",
        "id = '20210129180009136'\r\n",
        "get_news_title(id)\r\n",
        "get_news_content(id)\r\n",
        "get_news_comments(id)\r\n",
        "f.write(get_news_title(id) + ',' + get_news_content(id) + ',' + get_news_comments(id) + '\\n')\r\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dMXiEc5ZFhu"
      },
      "source": [
        "import io\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "result = '/content/test.csv'\r\n",
        "data = pd.read_csv(result)\r\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPd2fo7Hdl9U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}